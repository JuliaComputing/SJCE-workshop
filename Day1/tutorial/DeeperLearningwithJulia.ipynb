{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "minibatch (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using GZip\n",
    "\n",
    "function gzget(fname)\n",
    "    isfile(fname) || download(\"http://yann.lecun.com/exdb/mnist/$fname\", fname)\n",
    "    gzopen(fname) do f\n",
    "        return read(f)\n",
    "    end\n",
    "end\n",
    "\n",
    "function mnist()\n",
    "    xtrain = gzget(\"train-images-idx3-ubyte.gz\")[17:end]\n",
    "    xtest  = gzget(\"t10k-images-idx3-ubyte.gz\")[17:end]\n",
    "    ytrain = gzget(\"train-labels-idx1-ubyte.gz\")[9:end]\n",
    "    ytest  = gzget(\"t10k-labels-idx1-ubyte.gz\")[9:end]\n",
    "    return xtrain, xtest, ytrain, ytest\n",
    "end\n",
    "\n",
    "function minibatch(x, y, batchsz)\n",
    "    xrows     = 784\n",
    "    yrows     = 10\n",
    "    xscale    = 255\n",
    "    xbatch(a) = reshape(a./xscale, xrows, length(a).÷xrows)\n",
    "    ybatch(a) = (a[a.==0]=10; sparse(convert(Vector{Int},a),1:length(a),one(eltype(a)),yrows,length(a)))\n",
    "    xcols     = div(length(x),xrows)\n",
    "    xcols == length(y) || throw(DimensionMismatch())\n",
    "    data = Any[]\n",
    "    for i in 1:batchsz:xcols - batchsz + 1\n",
    "        j=i + batchsz - 1\n",
    "        push!(data, (xbatch(x[1 + (i - 1)*xrows:j*xrows]), ybatch(y[i:j])))\n",
    "    end\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function weights(h...)\n",
    "    w = Any[]\n",
    "    x = 28*28\n",
    "    for y in [h..., 10]\n",
    "        push!(w, 0.1*randn(y, x))\n",
    "        push!(w, zeros(y, 1))\n",
    "        x = y\n",
    "    end\n",
    "    w\n",
    "end\n",
    "\n",
    "function predict(w, x)\n",
    "    for i=1:2:length(w)\n",
    "        x = w[i]*x .+ w[i + 1]\n",
    "        if i < length(w) - 1\n",
    "            x = max(0, x)\n",
    "        end\n",
    "    end\n",
    "    x\n",
    "end\n",
    "\n",
    "function loss(w, x, y)\n",
    "    ypred = predict(w, x)\n",
    "    ynorm = logp(ypred, 1)\n",
    "    -sum(y.*ynorm)/size(y, 2)\n",
    "end\n",
    "\n",
    "function accuracy(w, samples)\n",
    "    correct   = 0\n",
    "    instances = 0\n",
    "    for (x, y) in samples\n",
    "        ypred      = predict(w, x)\n",
    "        correct   += sum(y.*(ypred .== maximum(ypred, 1)))\n",
    "        instances += size(y, 2)\n",
    "    end\n",
    "    correct/instances\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Knet\n",
    "\n",
    "∇loss = grad(loss)\n",
    "\n",
    "function train(w, samples; μ=.1)\n",
    "    for (x, y) in samples\n",
    "        ∇w = ∇loss(w, x, y)\n",
    "        for i in 1:length(w)\n",
    "            w[i] -= μ*∇w[i]\n",
    "        end\n",
    "    end\n",
    "    w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0.94487\t0.27930\n",
      "2\t0.96375\t0.95673\n",
      "3\t0.31270\t0.96284\n",
      "4\t0.99838\t0.96655\n",
      "5\t0.87210\t0.96795\n",
      "6"
     ]
    }
   ],
   "source": [
    "batchsz = 32\n",
    "\n",
    "w = weights(128, 64, 32)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = mnist()\n",
    "\n",
    "trainset = minibatch(xtrain, ytrain, batchsz)\n",
    "testset  = minibatch(xtest, ytest, batchsz)\n",
    "\n",
    "@time for epoch in 1:7\n",
    "    train(w, trainset)\n",
    "    @printf(\"%d\\t%.5f\\t%.5f\\n\", epoch, accuracy(w, trainset), accuracy(w, testset))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minibatch4(x, y, batchsz)\n",
    "    data = minibatch(x, y, batchsz)\n",
    "    for i=1:length(data)\n",
    "        (x, y)  = data[i]\n",
    "        data[i] = (reshape(x, (28, 28, 1, batchsz)), y)\n",
    "    end\n",
    "    data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function weights()\n",
    "    ϵ = 0.1\n",
    "    [\n",
    "        ϵ*randn(5, 5, 1, 20),\n",
    "        zeros(1, 1, 20, 1),\n",
    "        ϵ*randn(5, 5, 20, 50),\n",
    "        zeros(1, 1, 50, 1),\n",
    "        ϵ*randn(500, 800),\n",
    "        zeros(500, 1),\n",
    "        ϵ*randn(10, 500),\n",
    "        zeros(10, 1),\n",
    "    ]\n",
    "end\n",
    "\n",
    "function predict(w, x)\n",
    "    n = length(w) - 4\n",
    "    for i in 1:2:n\n",
    "        x = pool(max(conv4(w[i], x;padding=0) .+ w[i + 1], 0))\n",
    "    end\n",
    "    x = mat(x)\n",
    "    for i in n + 1:2:length(w) - 2\n",
    "        x = max(w[i]*x .+ w[i+1], 0)\n",
    "    end\n",
    "    return w[end - 1]*x .+ w[end]\n",
    "end\n",
    "\n",
    "function loss(w, x, y)\n",
    "    ypred = predict(w, x)\n",
    "    ynorm = logp(ypred, 1)\n",
    "    -sum(y.*ynorm)/size(y, 2)\n",
    "end\n",
    "\n",
    "function accuracy(w, samples)\n",
    "    correct   = 0\n",
    "    instances = 0\n",
    "    for (x, y) in samples\n",
    "        ypred      = predict(w, x)\n",
    "        correct   += sum(y.*(ypred .== maximum(ypred, 1)))\n",
    "        instances += size(y, 2)\n",
    "    end\n",
    "    correct/instances\n",
    "end\n",
    "\n",
    "using Knet\n",
    "\n",
    "∇loss = grad(loss)\n",
    "\n",
    "function train(w, data; μ=.1)\n",
    "    for (x, y) in data\n",
    "        ∇w = ∇loss(w, x, y)\n",
    "        for i in 1:length(w)\n",
    "            w[i] -= μ*∇w[i]\n",
    "        end\n",
    "    end\n",
    "    w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 32\n",
    "\n",
    "w = weights()\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = mnist()\n",
    "\n",
    "trainset = minibatch4(xtrain, ytrain, batchsz)\n",
    "testset  = minibatch4(xtest, ytest, batchsz)\n",
    "\n",
    "@printf(\"%d\\t%.5f\\t%.5f\\n\", 0, accuracy(w, trainset), accuracy(w, testset))\n",
    "\n",
    "# Experimental on CPU, run at your own risk.\n",
    "#@time for epoch in 1:8\n",
    "#    train(w, trainset)\n",
    "#    @printf(\"%d\\t%.5f\\t%.5f\\n\", epoch, accuracy(w, trainset), accuracy(w, testset))\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
